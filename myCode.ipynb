{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of classes 43\n",
      "Importing Classes\n",
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  \n",
      "(38999, 32, 32, 3)\n",
      "(38999,)\n",
      "(24959, 32, 32, 3)\n",
      "(7800, 32, 32, 3)\n",
      "(6240, 32, 32, 3)\n",
      "[0, 1427, 1410, 867, 1265, 1229, 270, 923, 933, 949, 1264, 834, 1372, 1379, 493, 390, 272, 682, 748, 134, 230, 207, 244, 340, 164, 955, 385, 164, 339, 181, 285, 519, 173, 450, 258, 766, 267, 136, 1314, 200, 215, 159, 167]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 60)        1560      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 60)        90060     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 30)        16230     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 30)          8130      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 30)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               240500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 43)                21543     \n",
      "=================================================================\n",
      "Total params: 378,023\n",
      "Trainable params: 378,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 905s 452ms/step - loss: 0.7816 - accuracy: 0.7745 - val_loss: 0.0900 - val_accuracy: 0.9720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score =  0.08317380424397879\n",
      "Test Accuracy =  0.9730769395828247\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "import pickle\n",
    "path = 'Train'\n",
    "testRatio=0.2\n",
    "valRatio =0.2\n",
    "imageDimensions = (32,32,3)\n",
    "\n",
    "images=[]\n",
    "classNo =[]\n",
    "myList = os.listdir(path)\n",
    "print(\"Total number of classes\", len(myList))\n",
    "noOfCLasses = len(myList)\n",
    "print(\"Importing Classes\")\n",
    "for x in range (1, noOfCLasses):\n",
    "    myPicList = os.listdir(path+\"/\"+str(x))\n",
    "    for y in myPicList:\n",
    "        curImg = cv2.imread(path+\"/\"+str(x)+\"/\"+y)\n",
    "        curImg = cv2.resize(curImg, (32,32))\n",
    "        images.append(curImg)\n",
    "        classNo.append(x)\n",
    "    print(x, end=\" \")\n",
    "print(\" \")\n",
    "\n",
    "\n",
    "images = np.array(images)\n",
    "classNo = np.array(classNo)\n",
    "\n",
    "print(images.shape)\n",
    "print(classNo.shape)\n",
    "\n",
    "######Splitting Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)\n",
    "X_train, X_validation, y_train, y_validation =train_test_split(X_train,y_train, test_size=valRatio)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_validation.shape)\n",
    "\n",
    "numOfSamples=[]\n",
    "for x in range(0, noOfCLasses):\n",
    "    numOfSamples.append(len(np.where(y_train==x)[0]))\n",
    "print(numOfSamples)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(range(0, noOfCLasses), numOfSamples)\n",
    "plt.title(\"Number of images\")\n",
    "plt.xlabel=(\"ID\")\n",
    "plt.ylabel(\"no\")\n",
    "plt.show()\n",
    "def preProcessing(img):\n",
    "    img=cv2.cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = img/255\n",
    "    return img\n",
    "\n",
    "X_train = np.array(list(map(preProcessing, X_train)))\n",
    "X_test = np.array(list(map(preProcessing, X_test)))\n",
    "X_validation = np.array(list(map(preProcessing, X_validation)))\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1],X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1],X_test.shape[2], 1)\n",
    "X_validation = X_validation.reshape(X_validation.shape[0], X_validation.shape[1],X_validation.shape[2], 1)\n",
    "\n",
    "dataGen = ImageDataGenerator(width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2,\n",
    "                             shear_range=0.1,\n",
    "                             rotation_range=10)\n",
    "dataGen.fit(X_train)\n",
    "\n",
    "y_train = to_categorical(y_train, noOfCLasses)\n",
    "y_test = to_categorical(y_test, noOfCLasses)\n",
    "y_validation = to_categorical(y_validation, noOfCLasses)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add((Conv2D(60, (5,5), input_shape=(32,32, 1), activation= 'relu')))\n",
    "model.add((Conv2D(60, (5,5), activation='relu')))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add((Conv2D(60//2, (3,3), activation='relu')))\n",
    "model.add((Conv2D(60//2, (3,3), activation= 'relu')))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(43, activation='softmax'))\n",
    "model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "epochVal = 1\n",
    "stepsPerEpoch = 2000\n",
    "history = model.fit_generator(dataGen.flow(X_train,y_train,\n",
    "                                 batch_size=50), steps_per_epoch=stepsPerEpoch, epochs=epochVal,\n",
    "                              validation_data=(X_validation, y_validation),\n",
    "                                shuffle=1)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel ='epoch'\n",
    "plt.figure(2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel= 'epoch'\n",
    "plt.show()\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Score = ', score[0])\n",
    "print('Test Accuracy = ', score[1])\n",
    "\n",
    "\n",
    "pickle_out = open(\"model_trained.p\", \"wb\")\n",
    "pickle.dump(model, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
